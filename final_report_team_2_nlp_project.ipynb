{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e5a551",
   "metadata": {},
   "source": [
    "# Final Report - Team 2 NLP Project\n",
    "\n",
    "Ella Xu, Jerry Nolf, Matthew Luna, Nathan Sharick - Innis Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737079c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631cfc0",
   "metadata": {},
   "source": [
    "### Project Description:\n",
    "\n",
    "- Most of the code hosting platforms for opensource projects consider the README file as the project introduction. As it is the first document seen by the reader, such a document needs to be crafted with care. The goal of this project is to predict the programming language for 100 repository by scraping, analyze the repository's README file contents. Using these datasets from 100 README's we were able to predict what programming language was used based on the composition of the README text.\n",
    "\n",
    "### Project Goal:\n",
    "\n",
    "- The goal of this project was to build a classification model that can predict the programming language of a repository based on the text of the repository's README.md file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb2e58",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71936ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matt_prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0f55b",
   "metadata": {},
   "source": [
    "### Data Acquisition, Data Cleaning, and Data Preparation\n",
    "\n",
    "- Web scraping methods were used to create a list of github username/repositories that included more than 300 repositories. The repositoriy names were pulled from github's top trending repositories, most forked repositories, and most stared repositories as of 05/13/ 2022.\n",
    "\n",
    "- The list of repositories was put into the acompanying acquire.py file which creates a list of dictionaries that includes the name of the repository, the programming language used in the repository, and the content of the readme file for each repository in the list, and saves it as a .json file. The .json file is required to reproduce this project with this notebook and can be created by saving the acquire.py file in your local repository and running 'python acquire.py' from the terminal.\n",
    "\n",
    "- Once the .json file is saved in the local directory is can be puled into the notebook, cleaned and prepared using the clean_df function located in the matt_prepare.py file. This function performs the following cleaning/preparation actions:\n",
    "    - It uses pandas to read the file into the notebook\n",
    "    \n",
    "    - It cleans the data by normalizing it, changing all words to lower case, and removing any characters that are not letters, numbers, or whitespace\n",
    "    \n",
    "    - It tokenizes the words in the readme content using a toktok tokenizer\n",
    "    \n",
    "    - It removes standard english stopwords from the readme content\n",
    "    \n",
    "    - It then outputs a dataframe with the following columns:\n",
    "        - name of the repository\n",
    "        \n",
    "        - Programming language of the repository\n",
    "        \n",
    "        - The raw readme contents\n",
    "        \n",
    "        - The cleaned readme content\n",
    "        \n",
    "        - The cleaned readme content that has been stemmed using a PorterStemmer\n",
    "        \n",
    "        - The cleaned readme content that has been lemmatized using a WordNetLemmatizer\n",
    "        \n",
    "        - The character count for the readme content\n",
    "        \n",
    "        - The word count for the readme content\n",
    "        \n",
    "- The dataset is then split into train, validate, and test sets using the split_data function located in the matt_prepare.py file which returns a train set with 56%, validate set with 24%, and test set with 20% of the original data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f12be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gocodeup/codeup-setup-script</td>\n",
       "      <td>Shell</td>\n",
       "      <td># Codeup Setup Script\\n\\nSetup script for Code...</td>\n",
       "      <td>codeup setup script\\n\\nsetup script for codeu...</td>\n",
       "      <td>codeup setup script setup script for codeup st...</td>\n",
       "      <td>codeup setup script setup script for codeup st...</td>\n",
       "      <td>1395</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gocodeup/movies-application</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># Movies Application\\n\\nFor this project, we w...</td>\n",
       "      <td>movies application\\n\\nfor this project we wil...</td>\n",
       "      <td>movi applic for thi project we will be build a...</td>\n",
       "      <td>movie application for this project we will be ...</td>\n",
       "      <td>4291</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>torvalds/linux</td>\n",
       "      <td>C</td>\n",
       "      <td>Linux kernel\\n============\\n\\nThere are severa...</td>\n",
       "      <td>linux kernel\\n\\n\\nthere are several guides for...</td>\n",
       "      <td>linux kernel there are sever guid for kernel d...</td>\n",
       "      <td>linux kernel there are several guide for kerne...</td>\n",
       "      <td>657</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rdpeng/ProgrammingAssignment2</td>\n",
       "      <td>R</td>\n",
       "      <td>### Introduction\\n\\nThis second programming as...</td>\n",
       "      <td>introduction\\n\\nthis second programming assig...</td>\n",
       "      <td>introduct thi second program assign will requi...</td>\n",
       "      <td>introduction this second programming assignmen...</td>\n",
       "      <td>3554</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>octocat/Spoon-Knife</td>\n",
       "      <td>HTML</td>\n",
       "      <td>### Well hello there!\\n\\nThis repository is me...</td>\n",
       "      <td>well hello there\\n\\nthis repository is meant ...</td>\n",
       "      <td>well hello there thi repositori is meant to pr...</td>\n",
       "      <td>well hello there this repository is meant to p...</td>\n",
       "      <td>710</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            repo    language  \\\n",
       "0   gocodeup/codeup-setup-script       Shell   \n",
       "1    gocodeup/movies-application  JavaScript   \n",
       "2                 torvalds/linux           C   \n",
       "4  rdpeng/ProgrammingAssignment2           R   \n",
       "5            octocat/Spoon-Knife        HTML   \n",
       "\n",
       "                                     readme_contents  \\\n",
       "0  # Codeup Setup Script\\n\\nSetup script for Code...   \n",
       "1  # Movies Application\\n\\nFor this project, we w...   \n",
       "2  Linux kernel\\n============\\n\\nThere are severa...   \n",
       "4  ### Introduction\\n\\nThis second programming as...   \n",
       "5  ### Well hello there!\\n\\nThis repository is me...   \n",
       "\n",
       "                                               clean  \\\n",
       "0   codeup setup script\\n\\nsetup script for codeu...   \n",
       "1   movies application\\n\\nfor this project we wil...   \n",
       "2  linux kernel\\n\\n\\nthere are several guides for...   \n",
       "4   introduction\\n\\nthis second programming assig...   \n",
       "5   well hello there\\n\\nthis repository is meant ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  codeup setup script setup script for codeup st...   \n",
       "1  movi applic for thi project we will be build a...   \n",
       "2  linux kernel there are sever guid for kernel d...   \n",
       "4  introduct thi second program assign will requi...   \n",
       "5  well hello there thi repositori is meant to pr...   \n",
       "\n",
       "                                          lemmatized  character_count  \\\n",
       "0  codeup setup script setup script for codeup st...             1395   \n",
       "1  movie application for this project we will be ...             4291   \n",
       "2  linux kernel there are several guide for kerne...              657   \n",
       "4  introduction this second programming assignmen...             3554   \n",
       "5  well hello there this repository is meant to p...              710   \n",
       "\n",
       "   word_count  \n",
       "0         203  \n",
       "1         768  \n",
       "2          97  \n",
       "4         620  \n",
       "5         112  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull in, clean, and prepare the dataset using the clean_df function\n",
    "df = matt_prepare.clean_df()\n",
    "#view the first five rows of the returned dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae01115b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 8), (65, 8), (54, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the dataset into train, validate, and test using the split_data function\n",
    "train, validate, test = matt_prepare.split_data(df)\n",
    "#view the row and column counts of the split dataframes\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd2495",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb576c",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "- Data exploration comments....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c69169",
   "metadata": {},
   "source": [
    "**Question 1:** What are the most common languages from the repos we explored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be019eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80742adf",
   "metadata": {},
   "source": [
    "**Question 2:** What are the most common words across all READme's?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074dac79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "451d53fd",
   "metadata": {},
   "source": [
    "**Question 3:** Does length of READme differ between languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40ada3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dba42d8b",
   "metadata": {},
   "source": [
    "**Question 4:** Are there any words that are found in all repos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322bb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846a8f50",
   "metadata": {},
   "source": [
    "**Question 5:** ........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa632b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bc69df0",
   "metadata": {},
   "source": [
    "### Takeaways from Data Exploration\n",
    "\n",
    "- Takeaway notes......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18ae84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f14607",
   "metadata": {},
   "source": [
    "### Data Preparation for Modeling\n",
    "\n",
    "- Notes on prep for modeling, bag of words, count vectorizer etc......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227e299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for data prep for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4691c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14601168",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "- Notes on modeling....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d92a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d8bd0",
   "metadata": {},
   "source": [
    "### Results from Modeling\n",
    "\n",
    "- Notes on modeling results ....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda393e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05275bd",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- Summary notes ....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2bc4e",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "- Notes for next steps ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7eb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
